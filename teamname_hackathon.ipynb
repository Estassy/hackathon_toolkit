{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d271c0b8",
   "metadata": {},
   "source": [
    "# Hackathon : Reinforcement Learning for Drone Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b59b4fd",
   "metadata": {},
   "source": [
    "- Team name: Olympus Coders\n",
    "- Team members names: Loan SAMAI, FarÃ¨s BENAGGOUNE, Marc Estassy BATABA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f6162-b5c3-462f-8c79-1fe99d16f175",
   "metadata": {},
   "source": [
    "## 0. Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68618ae7-0858-4006-be28-cd1451979861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 1)) (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: pygame in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 5)) (2.6.1)\n",
      "Requirement already satisfied: torch in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 6)) (2.6.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 7)) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mebataba\\appdata\\roaming\\python\\python311\\site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mebataba\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium->-r requirements.txt (line 4)) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\mebataba\\appdata\\roaming\\python\\python311\\site-packages (from gymnasium->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium->-r requirements.txt (line 4)) (0.0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 6)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 6)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 6)) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 6)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mebataba\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mebataba\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 6)) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dbd81fc-3ed3-4ecc-92da-ea4a86bb6261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import env\n",
    "import agent\n",
    "import reward\n",
    "import agent\n",
    "import simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca2c8db-cf8d-46d0-b8bb-ef4dba40009f",
   "metadata": {},
   "source": [
    "## 1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2817edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ DÃ©but de l'entraÃ®nement multi-configurations ðŸš€\n",
      "\n",
      "Fichier de checkpoint non trouvÃ©: multi_config_checkpoint.pth\n",
      "Ã‰pisode 1/3000, Reward: -4208.21\n",
      "Ã‰pisode 2/3000, Reward: -800.44\n",
      "Ã‰pisode 3/3000, Reward: -11901.36\n",
      "Ã‰pisode 4/3000, Reward: -6703.02\n",
      "Ã‰pisode 5/3000, Reward: -7421.37\n",
      "Ã‰pisode 6/3000, Reward: -11600.53\n",
      "Ã‰pisode 7/3000, Reward: -7055.84\n",
      "Ã‰pisode 8/3000, Reward: -13550.67\n",
      "Ã‰pisode 9/3000, Reward: -6537.49\n",
      "Ã‰pisode 10/3000, Reward: -18456.38\n",
      "Ã‰pisode 11/3000, Reward: -144.89\n",
      "Ã‰pisode 12/3000, Reward: -14446.20\n",
      "Ã‰pisode 13/3000, Reward: -3106.30\n",
      "Ã‰pisode 14/3000, Reward: -531.31\n",
      "Ã‰pisode 15/3000, Reward: -75.42\n",
      "Ã‰pisode 16/3000, Reward: -1837.37\n",
      "Ã‰pisode 17/3000, Reward: -19445.89\n",
      "Ã‰pisode 18/3000, Reward: -497.49\n",
      "Ã‰pisode 19/3000, Reward: -15764.71\n",
      "Ã‰pisode 20/3000, Reward: -25907.97\n",
      "Ã‰pisode 21/3000, Reward: -2584.17\n",
      "Ã‰pisode 22/3000, Reward: -97.26\n",
      "Ã‰pisode 23/3000, Reward: -39334.60\n",
      "Ã‰pisode 24/3000, Reward: -23425.53\n",
      "Ã‰pisode 25/3000, Reward: -7402.21\n",
      "Ã‰pisode 26/3000, Reward: -2993.46\n",
      "Ã‰pisode 27/3000, Reward: -827.14\n",
      "Ã‰pisode 28/3000, Reward: -4510.13\n",
      "Ã‰pisode 29/3000, Reward: -9816.96\n",
      "Ã‰pisode 30/3000, Reward: -10754.31\n",
      "Ã‰pisode 31/3000, Reward: -7109.79\n",
      "Ã‰pisode 32/3000, Reward: -6614.21\n",
      "Ã‰pisode 33/3000, Reward: -15222.90\n",
      "Ã‰pisode 34/3000, Reward: -2097.19\n",
      "Ã‰pisode 35/3000, Reward: -699.29\n",
      "Ã‰pisode 36/3000, Reward: -2702.09\n",
      "Ã‰pisode 37/3000, Reward: -12012.44\n",
      "Ã‰pisode 38/3000, Reward: -31163.52\n",
      "Ã‰pisode 39/3000, Reward: -8917.72\n",
      "Ã‰pisode 40/3000, Reward: -1200.98\n",
      "Ã‰pisode 41/3000, Reward: -29940.85\n",
      "Ã‰pisode 42/3000, Reward: -2398.13\n",
      "Ã‰pisode 43/3000, Reward: -5102.49\n",
      "Ã‰pisode 44/3000, Reward: -4697.34\n",
      "Ã‰pisode 45/3000, Reward: -199.72\n",
      "Ã‰pisode 46/3000, Reward: -13792.25\n",
      "Ã‰pisode 47/3000, Reward: -11601.88\n",
      "Ã‰pisode 48/3000, Reward: -15502.22\n",
      "Ã‰pisode 49/3000, Reward: -498.38\n",
      "Ã‰pisode 50/3000, Reward: -31307.64\n",
      "Ã‰pisode 51/3000, Reward: -18033.48\n",
      "Ã‰pisode 52/3000, Reward: -6907.19\n",
      "Ã‰pisode 53/3000, Reward: -12362.12\n",
      "Ã‰pisode 54/3000, Reward: -2201.99\n",
      "Ã‰pisode 55/3000, Reward: -60874.89\n",
      "Ã‰pisode 56/3000, Reward: -5158.05\n",
      "Ã‰pisode 57/3000, Reward: -3701.79\n",
      "Ã‰pisode 58/3000, Reward: -33719.76\n",
      "Ã‰pisode 59/3000, Reward: -31914.18\n",
      "Ã‰pisode 60/3000, Reward: -2422.32\n",
      "Ã‰pisode 61/3000, Reward: -7321.92\n",
      "Ã‰pisode 62/3000, Reward: -12870.54\n",
      "Ã‰pisode 63/3000, Reward: -1495.37\n",
      "Ã‰pisode 64/3000, Reward: -12212.74\n",
      "Ã‰pisode 65/3000, Reward: -13156.95\n",
      "Ã‰pisode 66/3000, Reward: -33155.23\n",
      "Ã‰pisode 67/3000, Reward: -2993.07\n",
      "Ã‰pisode 68/3000, Reward: -13509.67\n",
      "Ã‰pisode 69/3000, Reward: -12217.52\n",
      "Ã‰pisode 70/3000, Reward: -801.24\n",
      "Ã‰pisode 71/3000, Reward: -14455.80\n",
      "Ã‰pisode 72/3000, Reward: -3481.78\n",
      "Ã‰pisode 73/3000, Reward: -2298.14\n",
      "Ã‰pisode 74/3000, Reward: -9566.56\n",
      "Ã‰pisode 75/3000, Reward: -37019.60\n",
      "Ã‰pisode 76/3000, Reward: -78356.20\n",
      "Ã‰pisode 77/3000, Reward: -4301.16\n",
      "Ã‰pisode 78/3000, Reward: -6703.26\n",
      "Ã‰pisode 79/3000, Reward: -12103.99\n",
      "Ã‰pisode 80/3000, Reward: -3102.06\n",
      "Ã‰pisode 81/3000, Reward: -15628.35\n",
      "Ã‰pisode 82/3000, Reward: -3902.48\n",
      "Ã‰pisode 83/3000, Reward: -1498.08\n",
      "Ã‰pisode 84/3000, Reward: -22623.79\n",
      "Ã‰pisode 85/3000, Reward: -16025.91\n",
      "Ã‰pisode 86/3000, Reward: -901.73\n",
      "Ã‰pisode 87/3000, Reward: -1397.29\n",
      "Ã‰pisode 88/3000, Reward: -11011.23\n",
      "Ã‰pisode 89/3000, Reward: -1794.83\n",
      "Ã‰pisode 90/3000, Reward: -20912.57\n",
      "Ã‰pisode 91/3000, Reward: -22770.13\n",
      "Ã‰pisode 92/3000, Reward: -3396.60\n",
      "Ã‰pisode 93/3000, Reward: -39024.72\n",
      "Ã‰pisode 94/3000, Reward: -3597.93\n",
      "Ã‰pisode 95/3000, Reward: -1295.61\n",
      "Ã‰pisode 96/3000, Reward: -5301.23\n",
      "Ã‰pisode 97/3000, Reward: -3699.58\n",
      "Ã‰pisode 98/3000, Reward: -1200.02\n",
      "Ã‰pisode 99/3000, Reward: -3898.38\n",
      "Ã‰pisode 100/3000, Reward: -14603.27\n",
      "ðŸ’¾ Checkpoint sauvegardÃ© (Ã©pisode 100).\n",
      "Ã‰pisode 101/3000, Reward: -12518.21\n",
      "Ã‰pisode 102/3000, Reward: -32201.29\n",
      "Ã‰pisode 103/3000, Reward: -20050.98\n",
      "Ã‰pisode 104/3000, Reward: -1905.34\n",
      "Ã‰pisode 105/3000, Reward: -1098.74\n",
      "Ã‰pisode 106/3000, Reward: -797.92\n",
      "Ã‰pisode 107/3000, Reward: -27222.19\n",
      "Ã‰pisode 108/3000, Reward: -14913.46\n",
      "Ã‰pisode 109/3000, Reward: -13202.50\n",
      "Ã‰pisode 110/3000, Reward: -34125.21\n",
      "Ã‰pisode 111/3000, Reward: -649.15\n",
      "Ã‰pisode 112/3000, Reward: -2199.06\n",
      "Ã‰pisode 113/3000, Reward: -145170.14\n",
      "Ã‰pisode 114/3000, Reward: -4200.08\n",
      "Ã‰pisode 115/3000, Reward: -6201.29\n",
      "Ã‰pisode 116/3000, Reward: -8209.24\n",
      "Ã‰pisode 117/3000, Reward: -38549.67\n",
      "Ã‰pisode 118/3000, Reward: -17516.62\n",
      "Ã‰pisode 119/3000, Reward: -65.49\n",
      "Ã‰pisode 120/3000, Reward: -11048.18\n",
      "Ã‰pisode 121/3000, Reward: -11113.11\n",
      "Ã‰pisode 122/3000, Reward: -36517.90\n",
      "Ã‰pisode 123/3000, Reward: -69.29\n",
      "Ã‰pisode 124/3000, Reward: -13527.33\n",
      "Ã‰pisode 125/3000, Reward: -36322.25\n",
      "Ã‰pisode 126/3000, Reward: -2296.95\n",
      "Ã‰pisode 127/3000, Reward: -12418.62\n",
      "Ã‰pisode 128/3000, Reward: -11933.47\n",
      "Ã‰pisode 129/3000, Reward: -14709.17\n",
      "Ã‰pisode 130/3000, Reward: -7107.53\n",
      "Ã‰pisode 131/3000, Reward: -5706.75\n",
      "Ã‰pisode 132/3000, Reward: -5553.24\n",
      "Ã‰pisode 133/3000, Reward: -1096.97\n",
      "Ã‰pisode 134/3000, Reward: -37420.32\n",
      "Ã‰pisode 135/3000, Reward: -11009.38\n",
      "Ã‰pisode 136/3000, Reward: -37538.00\n",
      "Ã‰pisode 137/3000, Reward: -72.80\n",
      "Ã‰pisode 138/3000, Reward: -7457.09\n",
      "Ã‰pisode 139/3000, Reward: -129663.71\n",
      "Ã‰pisode 140/3000, Reward: -28626.65\n",
      "Ã‰pisode 141/3000, Reward: -1903.00\n",
      "Ã‰pisode 142/3000, Reward: -40308.63\n",
      "Ã‰pisode 143/3000, Reward: -10833.11\n",
      "Ã‰pisode 144/3000, Reward: -72.98\n",
      "Ã‰pisode 145/3000, Reward: -1418.23\n",
      "Ã‰pisode 146/3000, Reward: -13310.25\n",
      "Ã‰pisode 147/3000, Reward: -29315.05\n",
      "Ã‰pisode 148/3000, Reward: -5003.35\n",
      "Ã‰pisode 149/3000, Reward: -41824.30\n",
      "Ã‰pisode 150/3000, Reward: -45866.66\n",
      "Ã‰pisode 151/3000, Reward: -17905.69\n",
      "Ã‰pisode 152/3000, Reward: -37717.49\n",
      "Ã‰pisode 153/3000, Reward: -7206.43\n",
      "Ã‰pisode 154/3000, Reward: -7806.44\n",
      "Ã‰pisode 155/3000, Reward: -7299.60\n",
      "Ã‰pisode 156/3000, Reward: -92954.70\n",
      "Ã‰pisode 157/3000, Reward: -5301.80\n",
      "Ã‰pisode 158/3000, Reward: -39613.33\n",
      "Ã‰pisode 159/3000, Reward: -26123.18\n",
      "Ã‰pisode 160/3000, Reward: -2628.97\n",
      "Ã‰pisode 161/3000, Reward: -5007.23\n",
      "Ã‰pisode 162/3000, Reward: -13013.58\n",
      "Ã‰pisode 163/3000, Reward: -6609.63\n",
      "Ã‰pisode 164/3000, Reward: -16340.24\n",
      "Ã‰pisode 165/3000, Reward: -5704.75\n",
      "Ã‰pisode 166/3000, Reward: -23822.58\n",
      "Ã‰pisode 167/3000, Reward: -57222.52\n",
      "Ã‰pisode 168/3000, Reward: -12403.85\n",
      "Ã‰pisode 169/3000, Reward: -3214.41\n",
      "Ã‰pisode 170/3000, Reward: -14102.95\n",
      "Ã‰pisode 171/3000, Reward: -20917.03\n",
      "Ã‰pisode 172/3000, Reward: -1603.32\n",
      "Ã‰pisode 173/3000, Reward: -11201.57\n",
      "Ã‰pisode 174/3000, Reward: -32018.01\n",
      "Ã‰pisode 175/3000, Reward: -24925.70\n",
      "Ã‰pisode 176/3000, Reward: -8814.81\n",
      "Ã‰pisode 177/3000, Reward: -15009.83\n",
      "Ã‰pisode 178/3000, Reward: -3901.46\n",
      "Ã‰pisode 179/3000, Reward: -24219.64\n",
      "Ã‰pisode 180/3000, Reward: -16228.41\n",
      "Ã‰pisode 181/3000, Reward: -13104.79\n",
      "Ã‰pisode 182/3000, Reward: -612.01\n",
      "Ã‰pisode 183/3000, Reward: -6192.94\n",
      "Ã‰pisode 184/3000, Reward: -6398.57\n",
      "Ã‰pisode 185/3000, Reward: -6086.88\n",
      "Ã‰pisode 186/3000, Reward: -16327.93\n",
      "Ã‰pisode 187/3000, Reward: -6422.58\n",
      "Ã‰pisode 188/3000, Reward: -301.50\n",
      "Ã‰pisode 189/3000, Reward: -8907.69\n",
      "Ã‰pisode 190/3000, Reward: -19108.45\n",
      "Ã‰pisode 191/3000, Reward: -23279.52\n",
      "Ã‰pisode 192/3000, Reward: -1609.13\n",
      "Ã‰pisode 193/3000, Reward: -25935.96\n",
      "Ã‰pisode 194/3000, Reward: -7303.96\n",
      "Ã‰pisode 195/3000, Reward: -142397.36\n",
      "Ã‰pisode 196/3000, Reward: -4213.90\n",
      "Ã‰pisode 197/3000, Reward: -76.37\n",
      "Ã‰pisode 198/3000, Reward: -8224.48\n",
      "Ã‰pisode 199/3000, Reward: -9821.22\n",
      "Ã‰pisode 200/3000, Reward: -72.03\n",
      "ðŸ’¾ Checkpoint sauvegardÃ© (Ã©pisode 200).\n",
      "Ã‰pisode 201/3000, Reward: -26236.14\n",
      "Ã‰pisode 202/3000, Reward: -54287.44\n",
      "Ã‰pisode 203/3000, Reward: -13008.44\n",
      "Ã‰pisode 204/3000, Reward: -1902.98\n",
      "Ã‰pisode 205/3000, Reward: -19040.12\n",
      "Ã‰pisode 206/3000, Reward: -77.33\n",
      "Ã‰pisode 207/3000, Reward: -49567.07\n",
      "Ã‰pisode 208/3000, Reward: -7829.01\n",
      "Ã‰pisode 209/3000, Reward: -21047.50\n",
      "Ã‰pisode 210/3000, Reward: -12757.98\n",
      "Ã‰pisode 211/3000, Reward: -36539.72\n",
      "Ã‰pisode 212/3000, Reward: -497.78\n",
      "Ã‰pisode 213/3000, Reward: -6246.75\n",
      "Ã‰pisode 214/3000, Reward: -7207.06\n",
      "Ã‰pisode 215/3000, Reward: -97.50\n",
      "Ã‰pisode 216/3000, Reward: -24254.88\n",
      "Ã‰pisode 217/3000, Reward: -20533.84\n",
      "Ã‰pisode 218/3000, Reward: -49655.57\n",
      "Ã‰pisode 219/3000, Reward: -90133.06\n",
      "Ã‰pisode 220/3000, Reward: -118239.16\n",
      "Ã‰pisode 221/3000, Reward: -48155.71\n",
      "Ã‰pisode 222/3000, Reward: -19666.88\n",
      "Ã‰pisode 223/3000, Reward: -76.49\n",
      "Ã‰pisode 224/3000, Reward: -17959.51\n",
      "Ã‰pisode 225/3000, Reward: -32864.04\n",
      "Ã‰pisode 226/3000, Reward: -21386.25\n",
      "Ã‰pisode 227/3000, Reward: -138905.31\n"
     ]
    }
   ],
   "source": [
    "# On peut passer un seul fichier de configuration ou une liste de plusieurs configs\n",
    "# Exemple avec une seule config : trained_agent, all_rewards = simulate.multi_config_train([\"train_configs/config_1.json\"])\n",
    "# Exemple avec plusieurs configs : trained_agent, all_rewards = simulate.multi_config_train([\"train_configs/config_1.json\", \"train_configs/config_3.json\", \"train_configs/config_7.json\"])\n",
    "\n",
    "trained_agent, all_rewards = simulate.multi_config_train([\n",
    "    \"train_configs/config_small.json\",\n",
    "    \"train_configs/config_medium.json\",  # Commence par les environnements simples\n",
    "    \"train_configs/config_hybride.json\", # Progresse vers les hybrides\n",
    "    \"train_configs/config_hard.json\",    # Puis les difficiles\n",
    "    \"config.json\",                       # Inclut aussi la config par dÃ©faut pour complÃ©ter l'apprentissage\n",
    "], max_total_episodes=3000, checkpoint_path=\"multi_config_checkpoint.pth\", save_interval=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulated rewards per episode\n",
    "simulate.plot_cumulated_rewards(all_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac3652-834a-4943-a2f6-96dc395a21ae",
   "metadata": {},
   "source": [
    "## 2. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16713487-5971-4789-bc72-08bc1fb2dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_config_paths = [f\"./eval_configs/config_{i}.json\" for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ddc0a-19ce-4e67-996f-a19432201b6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained_agent = agent.MyAgent(...)\n",
    "trained_agent.load_checkpoint(\"multi_config_checkpoint_best.pth\")  # le meilleur\n",
    "all_results = simulate.evaluate(eval_config_paths, trained_agent, use_best_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e43948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82856a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages for each configuration\n",
    "averages = all_results.groupby('config_path').mean().reset_index().drop(columns=['episode'])\n",
    "averages = averages.rename(columns={\n",
    "    'steps': 'avg_steps',\n",
    "    'reward': 'avg_reward',\n",
    "    'evacuated': 'avg_evacuated',\n",
    "    'deactivated': 'avg_deactivated'})\n",
    "\n",
    "display(averages)\n",
    "averages.to_csv('averages.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
